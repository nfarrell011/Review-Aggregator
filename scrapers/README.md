## Web Scrapers
This folder contains the web scrapers that perform the data extraction. The scraper implementations are located in the scraper ```scrapper_classes``` folder. The scrapers are executed in the ```scarper_drivers``` folder.
___  

### Scraper Classes:  
There are $4$ scrapers in total. Each scraper performs the data extraction differently. ```BeautifulSoup``` is utilized whenever possible. However, many of the pages are loaded dynamically with ```Java Script``` causing this method to fail. To facilitate data extraction in these cases a bot is deployed using ```Selenium```.

**Scrapers**  
* ```YelpScraper```
  * Location:  ```/scapers/scaper_classes/yelp_scraper_class.py```
  * Extracts data from a user defined region (city, state)
  * See file for more details.  
  
* ```OpenTableScraperRestaurantList```
  * Location: ```/scapers/scaper_classes/open_table_scraper_restauarant_list.py```
  * Extracts data using a region specific list generated by the ```Yelp``` scraper.
  * See file for more details.

* ```OpenTableScraper```  **DISCONTINUED**
  * Location: ```/scapers/scaper_classes/open_table_scraper_region_class.py```.
  * This was the first implementation of the OpenTable scraper. The region search on the OpenTable is unreliable. The scraper is functional, but not used.
  * See file for more details.  

* ```GoogleScraper``` **UNDER DEVELOPMENT**
  * Location: ```/scapers/scaper_classes/google_scraper_class.py```.
  * This scraper is not yet completed.
  * See file for more details.  

___  

### Scraper Drivers

The data is extracted in two stages starting with the Yelp data. 

***Step 1: Get Yelp Data***
Execute the following script: ```/scapers/scraper_drivers/yelp_scraper_driver.py```  

In this file, the ```region``` parameter controls what location (city, state) the extract the data from.
```python     
    HOME = Path.cwd()
    URL = "https://www.yelp.com"
    region = "Portland, ME" # Update me! 
    business_type = "Restaurants"
    scraper = YelpScraper(URL, region, business_type)
    scraper.go_to_region()
    scraper.enter_business_type()
    scraper.navigate_pages_get_res_urls()
    scraper.remove_unwanted_urls()
    scraper.go_to_restaurant_url_extract_data() 
```

This will output $2$ csv files, which will located in: ```/data/raw/```:
1. ```yelp_restaurant_data_Portland_ME_2024-06-29.csv```
2. ```yelp_review_data_Portland_ME_2024-06-29.csv```  

***Step 2: Get OpenTable Data***
Execute the following script: ```/scapers/scraper_drivers/opentable_scraper_restaurant_list.py```

In this file, the data to scrape is provided via a list generated from the extracted Yelp restaurant data: ```"/data/raw/yelp_restaurant_data_Portland_ME_2024-06-29.csv"```

This is on ***line 33***

```python
# Use yelp as restaurant guide; i.e., run Yelp scraper first to extract restaurants in a region
yelp_res_data_df = pd.read_csv(str(HOME) + "/data/raw/yelp_restaurant_data_Portland_ME_2024-06-29.csv") # Update me!!
```

This will output $2$ csv files, which will located in: ```/data/raw/```:
1. ```open_table_restaurant_data_Portland_ME_2024-06-29.csv```
2. ```open_table_review_data_Portland_ME_2024-06-29.csv```  
___
### Data Transforming/Cleaning
The next step in the process is to transform the raw extracted data to a curated form ready to loaded in the database. This process is performed by the data transformers decribed in the data [Transformer README](/data_transformers/README.md)




